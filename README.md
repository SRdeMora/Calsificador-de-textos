<div align="center">
  <h1 align="center">
     Clasificador de Noticias por Categor铆a
  </h1>
  <p align="center">
    <strong>Un proyecto de Machine Learning para clasificar autom谩ticamente noticias en diferentes categor铆as (Deportes, Econom铆a, etc.) utilizando modelos cl谩sicos de NLP y Scikit-learn.</strong>
  </p>
</div>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white" alt="Jupyter">
  <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="scikit-learn">
  <img src="https://img.shields.io/badge/NLTK-3776AB?style=for-the-badge" alt="NLTK">
  <img src="https://img.shields.io/badge/Matplotlib-010101?style=for-the-badge&logo=matplotlib&logoColor=white" alt="Matplotlib">
</p>

---

##  Descripci贸n del Proyecto

Este repositorio contiene un notebook de Jupyter que detalla el proceso completo para construir y evaluar un **clasificador de textos multiclase**. El objetivo es entrenar un modelo de Machine Learning capaz de leer el contenido de una noticia y asignarle autom谩ticamente una de las siguientes categor铆as:

-   **Deportes**
-   **Econom铆a**
-   **Entretenimiento**
-   **Ciencia y Tecnolog铆a**
-   **Salud**

El proyecto abarca desde el preprocesamiento del texto hasta el entrenamiento, la evaluaci贸n comparativa de varios algoritmos y la visualizaci贸n de sus resultados.

---

## 锔 Pipeline del Proyecto

El flujo de trabajo implementado en el notebook sigue los pasos est谩ndar de un proyecto de Procesamiento del Lenguaje Natural (NLP):

### 1. Carga y Exploraci贸n de Datos

-   Se carga el dataset de noticias desde un archivo CSV.
-   Se realiza un an谩lisis exploratorio inicial para entender la distribuci贸n de las categor铆as y la estructura de los datos.

### 2. Preprocesamiento del Texto

Para preparar los datos para el modelado, se aplica una serie de t茅cnicas de limpieza y normalizaci贸n:
-   **Limpieza de Ruido:** Eliminaci贸n de caracteres no alfab茅ticos y puntuaci贸n.
-   **Conversi贸n a Min煤sculas:** Estandarizaci贸n del texto.
-   **Tokenizaci贸n:** Divisi贸n de los textos en palabras individuales (`tokens`) usando **NLTK**.
-   **Eliminaci贸n de Stopwords:** Filtrado de palabras comunes que no aportan significado (ej. "el", "la", "de").

### 3. Vectorizaci贸n de Texto

Los textos limpios se convierten en vectores num茅ricos para que los modelos de Machine Learning puedan procesarlos. Se utiliza la t茅cnica **TF-IDF (Term Frequency-Inverse Document Frequency)**, que asigna un peso a cada palabra en funci贸n de su importancia en el documento y en el corpus completo.

### 4. Entrenamiento y Evaluaci贸n de Modelos

Se entrenan y eval煤an cinco modelos de clasificaci贸n diferentes de la librer铆a **Scikit-learn** para comparar su rendimiento:
-   `LogisticRegression` (Regresi贸n Log铆stica)
-   `MultinomialNB` (Naive Bayes)
-   `SVC` (Support Vector Classifier)
-   `LinearSVC` (Linear Support Vector Classifier)
-   `DecisionTreeClassifier` (rbol de Decisi贸n)

Para cada modelo, se calcula su **precisi贸n (accuracy)** en el conjunto de prueba.

### 5. An谩lisis de Resultados

-   Se comparan las m茅tricas de precisi贸n de todos los modelos para identificar el de mejor rendimiento.
-   Se utiliza una **matriz de confusi贸n** para analizar en detalle los aciertos y errores del mejor modelo (`LinearSVC`), permitiendo visualizar qu茅 categor铆as son m谩s dif铆ciles de predecir.
-   Los resultados se visualizan mediante gr谩ficos de barras generados con **Matplotlib**.

---

##  Resultados

Tras la evaluaci贸n, el modelo **Linear Support Vector Classifier (LinearSVC)** demostr贸 ser el m谩s preciso para esta tarea, alcanzando una **precisi贸n superior al 95%** en la clasificaci贸n de noticias.

<div align="center">
  <!-- Recomiendo hacer una captura de pantalla de tus gr谩ficos y subirla al repo -->
  <img src="URL_DE_TUS_GRAFICOS.png" alt="Gr谩fico de Comparaci贸n de Modelos" width="700"/>
  <p><em>Comparativa de la precisi贸n de los modelos entrenados.</em></p>
</div>

---

##  C贸mo Utilizar este Notebook

1.  **Clona el repositorio:**
    ```sh
    git clone https://github.com/SRdeMora/Calsificador-de-textos.git
    cd Calsificador-de-textos
    ```

2.  **Crea un entorno virtual e instala las dependencias:**
    ```sh
    python -m venv venv
    source venv/bin/activate  # En macOS/Linux
    pip install -r requirements.txt 
    ```
    *(Nota: Aseg煤rate de crear un archivo `requirements.txt` en tu repositorio con `pip freeze > requirements.txt`)*

3.  **Inicia Jupyter Notebook:**
    ```sh
    jupyter notebook
    ```

4.  **Abre el archivo `Clasificador de textos.ipynb`** y ejecuta las celdas para replicar el an谩lisis.
