# -*- coding: utf-8 -*-
"""clasificadortexto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AqMZUCYN2XAneEGtxHRnWrqiERxoHd3r
"""

# app.py
import joblib
from flask import Flask, request, jsonify
from sklearn.feature_extraction.text import CountVectorizer
from nltk.stem import SnowballStemmer
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import nltk
from flask import Flask, request, jsonify
from flask_cors import CORS 
# Descargas necesarias
nltk.download('punkt')
nltk.download('stopwords')

app = Flask(__name__)
CORS(app)
# Carga el modelo y vectorizador (ajusta el nombre del archivo si lo guardaste distinto)
@app.route("/", methods=["GET"])
def home():
    return "<h1>API de Clasificación de Texto</h1><p>Usa /predict para obtener una categoría.</p>"


model = joblib.load('modelo.pkl')


vectorizer = joblib.load('vectorizador.pkl')

# Preprocesamiento
stemmer = SnowballStemmer('spanish')
stop_words = set(stopwords.words('spanish'))

def tokenize_stemmer(text):
    tokens = word_tokenize(text.lower())
    stems = [stemmer.stem(token) for token in tokens if token.isalpha() and token not in stop_words]
    return ' '.join(stems)

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json()
    text = data.get("text", "")
    processed_text = tokenize_stemmer(text)
    transformed = vectorizer.transform([processed_text])
    prediction = model.predict(transformed)[0]
    return jsonify({"category": prediction})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)

